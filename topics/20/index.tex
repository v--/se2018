\documentclass{../../common/topic}

\TopicSetup
{
  number=20,
  title={Точкови и интервални оценки за параметрите на нормалното разпределение.},
  basedate={4 юли 2019},
  author={Янис Василев}
}

% Bibliography
\addbibresource{./references.bib}

\begin{document}

\maketitle

\section{Теория}

Общата теория е базирана на \cite{ДимитровЯнев2007}, а оценките за нормалното разпределение - на \cite{Въндев2002ЛекцииТом1}.

\subsection{Анотация}

Изложената анотацията е взета от \cite{Syllabus}.

\begin{enumerate}
  \item Определения за точкови и интервални оценки.
  \item Свойства на точковите оценки.
  \item Неравенство на Рао-Крамер.
  \item Доверителни интервали за параметрите на нормалното разпределение.
\end{enumerate}

\subsection{Основни понятия}

Считаме, че е зададено вероятностно пространство \( (\Omega, \mscrF, \Prob) \).

\begin{definition}[Извадки]
  Нека \( \xi \) е случайна величина над \( (\Omega, \mscrF, \Prob) \). Множеството от елементарни събития \( \Omega \) в статистиката често се нарича \textbf{генерална съвкупност}.

  \begin{itemize}
    \item Ако случайните величини \( \xi_1, \ldots, \xi_n \) са независими две по две и имат същото разпределение като \( \xi \), казваме, че \( \xi_1, \ldots, \xi_n \) са \textbf{наблюдения} над \( \xi \) и че те са \textbf{проста извадка} с обем \( n \) над генералната съвкупност \( \Omega \). Понякога ги разглеждаме и като случаен вектор \( \vect{\xi_n} = (\xi_1, \ldots, \xi_n) \).
    \item \textbf{Функция на правдоподобие} \( l_\xi(x) \) на случайната величина \( \xi \) наричаме, в абсолютно непрекъснатия случай, плътността на \( \xi \) или, в дискретния случай, функцията на вероятностите на \( \xi \).
    \item \textbf{Функция на правдоподобие} \( l(x_1, \ldots, x_n) \) на извадката \( \xi_1, \ldots, \xi_n \) наричаме функцията на правдоподобие на случайния вектор \( \vect{\xi_n} \). При извадки от независими случайни величини, функцията на правдоподобие на извадката е произведение на индивидуалните функции на правдоподобие.
    \item \textbf{Извадково} пространство, съответстващо на извадката \( \xi_1, \ldots, \xi_n \), наричаме множеството \( \mscrX \subseteq \BbbR^n \) от стойности на случайния вектор \( \vect{\xi_n} \).
    \item \textbf{Реализации} на извадката наричаме вектори от \( \mscrX \). Те моделират истинските данни в математическата статистика, съпоставяйки ги на \enquote{теоретичната} извадка \( \xi_1, \ldots, \xi_n \).
  \end{itemize}
\end{definition}

\begin{definition}[Оценки]
  Нека \( \xi_1, \ldots \xi_n \) е проста извадка над случайната величина \( \xi \), чието разпределение не ни е известно. Целта ни е на базата на тази извадка да оценим някакви числени характеристики \( \theta = (\theta_1, \ldots, \theta_m) \) на \( \xi \), които напълно да определят разпределението на \( \xi \). Обикновено \( \theta \) е вектор от моменти на \( \xi \) или, в параметричната статистика, \( \theta \) е някой от параметрите на класът от разпределения, на който се предполага, че принадлежи \( \xi \). Условна вероятност при условие, че \( \theta = \alpha \) е конкретна стойност на вектора, бележим с
  \begin{align*}
    \Prob(\cdot \given \theta = \alpha)
    &&\text{ или}&&
    \Prob(\cdot \given \alpha).
  \end{align*}

  Множеството от всички възможни стойности на \( \theta \) ще бележим с \( \Theta \).

  \begin{itemize}
    \item \textbf{Статистика} наричаме всяка измерима функция на извадката. По определение статистиките са случайни величини.

    \item Ако \( \theta = (\theta_1, \ldots, \theta_m) \) са някакви числени характеристика на \( \xi \) и статистиката \( t_n = t_n(x_1, \ldots, x_n) \) не зависи от \( \theta \), казваме, че \( t_n \) е \textbf{точкова оценка} за \( \theta \).

    \item Стойността \( t_n - \Expect(t_n \given \theta) \) наричаме \textbf{случайна грешка}, а стойността \( \Expect(t_n \given \theta) - \theta \) наричаме \textbf{систематична грешка} или \textbf{изместване} на оценката. Разликата
    \begin{equation*}
      t_n - \theta = t_n - \Expect(t_n \given \theta) + \Expect(t_n \given \theta) - \theta
    \end{equation*}
    се разпада на систематична и случайна грешка.

    \item Точковата оценка \( t_n \) за \( \theta \) наричаме \textbf{неизместена}, ако \( \Expect(t_n \given \theta) = \theta \), и асимптотично неизместена, ако \( \Expect(t_n \given \theta) \xrightarrow[n \to \infty]{} \theta \).

    \item Точковата оценка \( t_n \) за \( \theta \) наричаме \textbf{състоятелна}, ако \( t_n \xrightarrow[n \to \infty]{} \theta \) по вероятност, т.е.
    \begin{equation*}
      \Prob(\abs{t_n - \theta} > \varepsilon \given \theta) \xrightarrow[n \to \infty]{} 0\quad\forall \varepsilon > 0.
    \end{equation*}

    Оценката наричаме \textbf{силно състоятелна}, ако сходимостта е почти сигурна, т.е.
    \begin{equation*}
      \Prob(\sup_{k \geq n} \abs{t_k - \theta} > \varepsilon \given \theta) \xrightarrow[n \to \infty]{} 0\quad\forall \varepsilon > 0.
    \end{equation*}

    \item Точковата оценка \( t_n \) за \( \theta \) с изместване \( \Expect(t_n) - \theta \) има \textbf{минимална дисперсия}, ако \( \var(t_n) \leq \var(u_n) \) за произволна друга точкова оценка \( u_n \) със същото изместване.

    \item Ако векторът \( \theta \) е едномерен (т.е. \( \theta \) е число), \textbf{интервална оценка} с ниво на доверие \( \gamma \) за \( \theta \) наричаме двойка точкови оценки \( a_n \) и \( b_n \) за \( \theta \), за които
    \begin{equation*}
      \Prob(a_n \leq \theta \leq b_n \given \theta) = \gamma
    \end{equation*}
    независимо от стойността на \( \theta \).
  \end{itemize}
\end{definition}

\begin{proposition}\label{thm:mean_is_unbiased_estimator}
  За произволна случайна величина \( \xi \) с крайно очакване средноаритметичното
  \begin{equation*}
    m_n(x_1, \ldots, x_n) \coloneqq \frac 1 n \sum_{k=1}^n x_k
  \end{equation*}
  е неизместена оценка за \( \Expect(\xi) \).
\end{proposition}
\begin{proof}
  Следва директно от линейността на очакването.
\end{proof}

\begin{proposition}\label{thm:corrected_variation_is_unbiased_estimator}
  За произволна случайна величина \( \xi \) с крайна дисперсия оценката
  \begin{equation*}
    s_n^2(x_1, \ldots, x_n) \coloneqq \frac 1 {n-1} \sum_{k=1}^n {(x_k - \hat \xi(x_1, \ldots, x_n))}^2
  \end{equation*}
  е неизместена оценка за \( \var(\xi) \).
\end{proposition}
\begin{proof}
  Разписваме \( s_n^2 \)
  \begin{balign*}
    s_n^2(\xi_1, \ldots, \xi_n)
    &=
    \frac 1 {n-1} \sum_{i=1}^n {(\xi_i - \hat \xi(\xi_1, \ldots, \xi_n))}^2
    = \\ &=
    \frac 1 {n-1} \sum_{i=1}^n \bracks*{\xi_i^2 - \frac 2 n \sum_{j=1}^n \xi_i \xi_j + \frac 1 {n^2} {\parens*{ \sum_{j=1}^n \xi_m }}^2 }
    = \\ &=
    \frac 1 {n-1} \sum_{i=1}^n \bracks*{\xi_i^2 - \frac 2 n \sum_{j=1}^n \xi_i \xi_j + \frac 1 {n^2} \sum_{j=1}^n \sum_{k=1}^n \xi_j \xi_k }
    = \\ &=
    \frac 1 {n-1} \sum_{i=1}^n \xi_i^2 - \frac 2 {n(n-1)} \sum_{i=1}^n \sum_{j=1}^n \xi_i \xi_j + \frac n {n^2 (n-1)} \sum_{j=1}^n \sum_{k=1}^n \xi_j \xi_k
    = \\ &=
    \frac 1 {n-1} \sum_{i=1}^n \xi_i^2 - \frac 1 {n(n-1)} \sum_{i=1}^n \sum_{j=1}^n \xi_i \xi_j
    = \\ &=
    \parens*{\frac 1 {n-1} - \frac 1 {n(n-1)} } \sum_{i=1}^n \xi_i^2 - \frac 1 {n(n-1)} \sum_{i=1}^n \sum_{\substack{j=1 \\ j\neq i}}^n \xi_i \xi_j
    = \\ &=
    \frac 1 n \sum_{i=1}^n \xi_i^2 - \frac 1 {n(n-1)} \sum_{i=1}^n \sum_{\substack{j=1 \\ j\neq i}}^n \xi_i \xi_j.
  \end{balign*}

  Като вземем очакване, получаваме
  \begin{align*}
    \Expect(s_n^2 \given \theta)
    &=
    \frac 1 n \sum_{i=1}^n \Expect(\xi_i^2 \given \theta) - \frac 1 {n(n-1)} \sum_{i=1}^n \sum_{\substack{j=1 \\ j\neq i}}^n \Expect(\xi_i \xi_j \given \theta)
    = \\ &=
    \frac 1 n \sum_{i=1}^n \Expect(\xi_i^2 \given \theta) - \frac 1 {n(n-1)} \sum_{i=1}^n \sum_{\substack{j=1 \\ j\neq i}}^n \Expect(\xi_i \given \theta) \Expect(\xi_j \given \theta)
    = \\ &=
    \frac 1 n \sum_{i=1}^n \Expect(\xi^2 \given \theta) - \frac 1 {n(n-1)} \sum_{i=1}^n \sum_{\substack{j=1 \\ j\neq i}}^n {\Expect(\xi \given \theta)}^2
    = \\ &=
    \frac n n \Expect(\xi^2 \given \theta) - \frac {n(n-1)} {n(n-1)} {\Expect(\xi \given \theta)}^2
    = \\ &=
    \Expect(\xi^2 \given \theta) - {\Expect(\xi \given \theta)}^2
    = \\ &=
    \var(\xi^2 \given \theta).
  \end{align*}
\end{proof}

\subsection{Информация на Фишър}

\begin{definition}\label{def:fisher_information}
  Нека \( \theta \in \Theta \) е числена характеристика на \( \xi \), т.е. \( \theta \) е едномерен вектор с възможни стойности в \( \Theta \).

  Разглеждаме \textbf{логаритмичната функция на правдоподобие} \( \ln l_\xi(x \given \theta) \). За нея ще изискаме допълнителни условия за регулярност:
  \begin{enumerate}
    \item Множеството \( \set{ x \in \BbbR \given l_\xi(x \given \theta) = 0 } \), в което не е дефинирана \( \ln l_\xi(x \given \theta) \), има вероятност \( 0 \) независимо от \( \theta \). Така очакването на \( \ln l_\xi(x \given \theta) \) е дефинирано почти навсякъде.
    \item Функцията \( \ln l_\xi(x \given \theta) \) е диференцируема по \( \theta \) за (почти) всяко \( x \) от дефиниционната си област.
    \item За произволно \( \theta \in \Theta \) са изпълнени условията за диференциране под очакването
    \begin{equation*}
      \frac {\partial \Expect(\ln l_\xi(x \given \theta) \given \theta)} {\partial \theta}
      =
      \Expect\parens*{ \frac {\partial \ln l_\xi(x \given \theta) \given \theta)} {\partial \theta} }.
    \end{equation*}
  \end{enumerate}

  \textbf{Информация на Фишър} за \( \theta \) на \( \xi \) наричаме очакването
  \begin{equation*}
    \mscrI_\xi(\theta) \coloneqq \var\parens*{ \frac {\partial \ln l_\xi(\xi \given \theta)} {\partial \theta} \given* \theta }.
  \end{equation*}

  Естествено, \( \mscrI_\xi(\theta) \) може и да не съществува.

  \textbf{Информация на Фишър} за \( \theta \) на извадката \( \xi_1, \ldots, \xi_n \) над \( \xi \) наричаме информация на Фишър за \( \theta \) на случайния вектор \( (\xi_1, \ldots, \xi_n) \). За прости извадки от независими случайни величини имаме
  \begin{equation*}
    \mscrI_{(\xi_1, \ldots, \xi_n)}(\theta) = n \mscrI_\xi(\theta).
  \end{equation*}
\end{definition}

\begin{remark}
  Третото условие за регулярност не е необходимо за определението на информация на Фишър, но е необходимо за доказателство на свойствата ѝ.
\end{remark}

\begin{theorem}
  \hfill
  \begin{enumerate}
    \item Ако информацията \( \mscrI_\xi(\theta) \) съществува, тогава
    \begin{equation*}
      \mscrI_\xi(\theta) = \Expect\parens*{ {\parens*{ \frac {\partial \ln l_\xi(\xi \given \theta)} {\partial \theta} \given* \theta }}^2 }.
    \end{equation*}

    \item Ако освен това логаритмичното правдоподобие \( \ln l_\xi (x \given \theta) \) е двукратно диференцируемо по \( \theta \) и \( \ln l_\xi \) позволява двукратно диференциране под очакването, имаме
    \begin{equation*}
      \mscrI_\xi(\theta) = -\Expect\parens*{ \frac {\partial^2 \ln l_\xi(\xi \given \theta)} {\partial \theta^2} \given* \theta }.
    \end{equation*}
  \end{enumerate}
\end{theorem}
\begin{proof}
  Ще докажем теоремата само за абсолютно непрекъснати разпределения. В общия случай римановите интеграли могат да се заменят с интеграли по вероятностни мерки, съответстващи на различните параметри \( \theta \in \Theta \).
  \begin{enumerate}
    \item Разглеждаме очакването
    \begin{align*}
      \Expect\parens*{ \frac {\partial \ln l_\xi(\xi \given \theta)} {\partial \theta} \given* \theta }
      &=
      \int_{\BbbR} \frac {\partial \ln l_\xi(x \given \theta)} {\partial \theta} l_\xi(x \given \theta) dx
      = \\ &=
      \int_{\BbbR} \frac {\partial l_\xi(x \given \theta)} {\partial \theta} \frac {l_\xi(x \given \theta)} {l_\xi(x \given \theta)} dx
      = \\ &=
      \frac \partial {\partial \theta} \int_{\BbbR} l_\xi(x \given \theta) dx
      = \\ &=
      \frac {\partial 1} {\partial \theta}
      =
      0.
    \end{align*}

    Тогава
    \begin{align*}
      \mscrI_\xi(\theta)
      &=
      \var\parens*{ \frac {\partial \ln l_\xi(\xi \given \theta)} {\partial \theta} \given* \theta }
      = \\ &=
      \Expect\parens*{ {\parens*{ \frac {\partial \ln l_\xi(\xi \given \theta)} {\partial \theta} \given* \theta }}^2 } + {\parens*{\Expect\parens*{ \frac {\partial \ln l_\xi(\xi \given \theta)} {\partial \theta} \given* \theta }}}^2
      = \\ &=
      \Expect\parens*{ {\parens*{ \frac {\partial \ln l_\xi(\xi \given \theta)} {\partial \theta} \given* \theta }}^2 }.
    \end{align*}

    \item Директно пресмятаме
    \begin{align*}
      &\quad\Expect\parens*{ \frac {\partial^2 \ln l_\xi(\xi \given \theta)} {\partial \theta^2} \given* \theta }
      = \\ &=
      \int_{\BbbR} \frac {\partial^2 \ln l_\xi(x \given \theta)} {\partial \theta^2} l_\xi(x \given \theta) dx
      = \\ &=
      \int_{\BbbR} \frac \partial {\partial \theta} \parens*{\frac 1 {l_\xi(x \given \theta)} \cdot \frac {\partial l_\xi(x \given \theta)} {\partial \theta} } \cdot l_\xi(x \given \theta) dx
      = \\ &=
      \int_{\BbbR} \frac 1 {{(l_\xi(x \given \theta))}^2} \cdot \parens*{ \frac {\partial^2 l_\xi(x \given \theta)} {\partial \theta^2} \cdot l_\xi(x \given \theta) - {\parens*{\frac {\partial l_\xi(x \given \theta)} {\partial \theta} }}^2 } \cdot l_\xi(x \given \theta) dx
      = \\ &=
      \int_{\BbbR} \frac {\partial^2 l_\xi(x \given \theta)} {\partial \theta^2} dx - \int_{\BbbR} {\parens*{\frac {\partial l_\xi(x \given \theta)} {\partial \theta} }}^2 \frac 1 {l_\xi(x \given \theta)} dx
      = \\ &=
      \frac {\partial^2} {\partial \theta^2} \int_{\BbbR} l_\xi(x \given \theta) dx - \int_{\BbbR} {\parens*{\frac {\partial \ln l_\xi(x \given \theta)} {\partial \theta} \cdot l_\xi(x \given \theta) }}^2 \frac 1 {l_\xi(x \given \theta)} dx
      = \\ &=
      -\mscrI_\xi(\theta).
    \end{align*}
  \end{enumerate}
\end{proof}

\subsection{Ефективни оценки}

\begin{definition}
  Казваме, че неизместената точкова оценка \( t_n \) на числената характеристика \( \theta \) за случайната величина \( \xi \) е \textbf{ефективна}, ако
  \begin{equation*}
    \var(t_n \given \theta) = \var(t_n(\xi_1, \ldots, \xi_n) \given \theta) = \frac 1 {\mscrI_\xi(\theta)}.
  \end{equation*}

  Разбира се, това изисква за \( l_\xi(x \given \theta) \) да бъдат изпълнени условията за регулярност.
\end{definition}

\begin{theorem}
  Ако за вектор от числени характеристики \( \theta = (\theta_1, \ldots, \theta_m) \) на случайната величина \( \xi \) съществува неизместена оценка с минимална дисперсия, тя е единствена.
\end{theorem}
\begin{proof}
  Нека \( t_n \) и \( u_n \) са неизместени оценки за \( \theta \) с минимална дисперсия \( d^2 \). Ще докажем, че те са равни.

  Нека \( u_n = (t_n + u_n) / 2 \). Поради линейността на очакването, \( v_n \) също е неизместена оценка на \( \theta \). За дисперсията на \( v_n \) имаме
  \begin{equation*}
    \var(v_n \given \theta)
    =
    \frac 1 4 \Expect \parens*{ {(t_n + u_n)}^2 \given \theta }
    =
    \frac 1 4 [\var(t_n \given \theta) + \var(u_n \given \theta) + 2 \cov(t_n, u_n \given \theta)].
  \end{equation*}

  Неравенството на Коши-Буняковски-Шварц ни дава
  \begin{equation*}
    \cov(t_n, u_n \given \theta)
    =
    \Expect(t_n u_n \given \theta)
    \leq
    \sqrt {\Expect(t_n^2 \given \theta) \Expect(u_n^2 \given \theta)}
    =
    d^2.
  \end{equation*}

  Така получихме \( \var(v_n \given \theta) \leq d^2 \). Тъй като дисперсията \( d^2 \) е минимална, строгото неравенство \( \var(v_n \given \theta) < d^2 \) няма как да е изпълнено. Остава \( \var(v_n \given \theta) = \cov(t_n, u_n \given \theta) = d^2 \) и значи в горното неравенство се достига равенство.

  Но равенство в неравенството на Коши-Буняковски-Шварц може да се достигне единствено когато \( t_n \) и \( u_n \) са линейно зависими, т.е. \( t_n = \alpha u_n \) за някое \( \alpha \in \BbbR \setminus \set{ 0 } \). Тогава
  \begin{equation*}
    d^2 = \var(t_n \given \theta) = \alpha^2 \var(u_n \given \theta) = d^2,
  \end{equation*}
  следователно \( \alpha = 1 \) и \( t_n = u_n \).
\end{proof}

\begin{theorem}[Рао-Крамер]
  Ефективните оценки имат минимална дисперсия.
\end{theorem}

Ще докажем малко по-общ резултат, който улеснява проверката и даже намирането на ефективни оценки.
\begin{theorem}[Рао-Крамер]\label{thm:rao_cramer}
  Нека \( \theta \) е някаква числена характеристика на \( \xi \) е \( r'(\theta) \) е диференцируема в \( \Theta \). Нека са изпълнени условията за регулярност от \cref{def:fisher_information}.

  За всяка неизместена оценка \( t_n \) на \( r(\theta) \) е изпълнено
  \begin{equation*}
    \var(t_n \given \theta) \geq \frac {{\bracks*{r'(\theta) }}^2} {n \mscrI_\xi(\theta)},
  \end{equation*}
  като равенство се достига тогава и само тогава, когато производната на логаритмичното правдоподобие на извадката \( \xi_1, \ldots, \xi_n \) допуска представяне
  \begin{equation*}
    \frac {\partial \ln l(x_1, \ldots, x_n \given \theta)} {\partial \theta}
    =
    k(\theta) [t_n(x_1, \ldots, x_n) + r(\theta)],
  \end{equation*}
  където \( k: \Theta \to \BbbR \) не зависи от \( x_1, \ldots, x_n \).
\end{theorem}
\begin{proof}
  Отново ще докажем теоремата само за абсолютно непрекъснати разпределения. В общия случай римановите интеграли могат да се заменят с интеграли по вероятностни мерки, съответстващи на различните параметри \( \theta \in \Theta \).

  Диференцираме интегралите
  \begin{align*}
     1 &= \int_{\BbbR^n} l(x_1, \ldots, x_n \given \theta) dx_1 \ldots dx_n,
     \\
     \Expect(t_n \given \theta) &= \int_{\BbbR^n} l(x_1, \ldots, x_n \given \theta) t(x_1, \ldots, x_n) dx_1 \ldots dx_n.
  \end{align*}
  по \( \theta \)
  \begin{align*}
     0 &= \int_{\BbbR^n} \frac {\partial l(x_1, \ldots, x_n \given \theta)} {\partial \theta} dx_1 \ldots dx_n,
     \\
     r'(\theta) &= \int_{\BbbR^n} \frac {\partial l(x_1, \ldots, x_n \given \theta)} {\partial \theta} t(x_1, \ldots, x_n) dx_1 \ldots dx_n.
  \end{align*}

  Тогава
  \begin{align*}
    r'(\theta)
    &=
    r'(\theta) - 0 \cdot r(\theta)
    = \\ &=
    \int_{\BbbR^n} \frac {\partial l(x_1, \ldots, x_n \given \theta)} {\partial \theta} \cdot [t(x_1, \ldots, x_n) - r(\theta)] dx_1 \ldots dx_n
    = \\ &=
    \int_{\BbbR^n} \frac {\partial \ln l(x_1, \ldots, x_n \given \theta)} {\partial \theta} \cdot l(x_1, \ldots, x_n) \cdot [t(x_1, \ldots, x_n) - r(\theta)] dx_1 \ldots dx_n
    = \\ &=
    \Expect \parens*{ \frac {\partial \ln l(\xi_1, \ldots, \xi_n \given \theta)} {\partial \theta} \cdot [t(\xi_1, \ldots, \xi_n) - r(\theta)] \given* \theta }.
  \end{align*}

  От неравенството на Коши-Буняковски-Шварц получаваме
  \begin{align*}
    {\parens*{r'(\theta) }}^2
    &=
    {\parens*{ \Expect \parens*{ \frac {\partial \ln l(\xi_1, \ldots, \xi_n \given \theta)} {\partial \theta} \cdot [t(\xi_1, \ldots, \xi_n) - r(\theta)] \given* \theta }}}^2
    \leq \\ &\leq
    \Expect \parens*{ {\parens*{\frac {\partial \ln l(\xi_1, \ldots, \xi_n \given \theta)} {\partial \theta} }}^2 \given* \theta } \cdot \Expect \parens*{ {\bracks*{t(\xi_1, \ldots, \xi_n) - r(\theta) }}^2 \given* \theta }
    = \\ &=
    n \mscrI_\xi(\theta) \var \parens{ t_n \given \theta },
  \end{align*}
  като равенство се достига, когато за някоя зависеща от \( \theta \) константа \( k(\theta) \) е изпълнено
  \begin{equation*}
    \frac {\partial \ln l(x_1, \ldots, x_n \given \theta)} {\partial \theta} = k(\theta) (t(x_1, \ldots, x_n) - r(\theta)).
  \end{equation*}
\end{proof}

\subsection{Нормално разпределение}

Нека \( \xi \in \distr{No}(\mu, \sigma^2) \) и \( \xi_1, \ldots, \xi_n \) е проста извадка над \( \xi \).

\begin{proposition}\label{thm:normal_mean_variance_estimators_independent}
  Оценките \( m_n \) и \( s_n^2 \) за \( \distr{No}(\mu, \sigma^2) \)-разпределена извадка са независими. За разпределенията им имаме
  \begin{equation*}
    m_n \in \distr{No} \parens*{\mu, \frac {\sigma^2} n },
    \\
    (n-1) \frac {s_n^2} {\sigma^2} \in \distr{\chi^2}(n-1).
  \end{equation*}
\end{proposition}
\begin{proof}
  Този факт следва от теоремата на Кокрън. Наистина, нека \( \eta_k = \frac {\xi_k - \mu} \sigma, k = 1, \ldots, n \).

  Разглеждаме квадратичните форми
  \begin{align*}
    (n-1) s_n^2(\eta_1, \ldots, \eta_n)
    &=
    \sum_{k=1}^n \xi_k^2 - {[\sqrt n \cdot m_n(\eta_1, \ldots, \eta_n)]}^2,
    \\
    \sum_{i=1}^n {\parens*{\eta_i - \frac 1 n \sum_{j=1}^n \eta_j }}^2
    &=
    \sum_{k=1}^n \eta_k^2 - \frac 1 n {\parens*{\sum_{k=1}^n \eta_k }}^2,
    \\
    \vect{\eta_n}^T \parens*{I_n - \frac 1 n 1_n } \vect{\eta_n}
    &=
    \vect{\eta_n}^T I_n \vect{\eta_n} - \vect{\eta_n}^T \parens*{\frac 1 n 1_n } \vect{\eta_n},
  \end{align*}
  където с \( I_n \) сме означили единичната \( n \times n \) матрица и
  \begin{align*}
    1_n
    \coloneqq
    \begin{pmatrix}
      1 & \cdots & 1 \\
      \vdots & \ddots & \vdots \\
      1 & \cdots & 1
    \end{pmatrix}.
  \end{align*}

  Имаме равенство и за ранговете на матриците на квадратичните форми, т.е.
  \begin{equation*}
    \parens*{I_n - \frac 1 n 1_n } = \rank I_n - \rank \parens*{ \frac 1 n 1_n }.
  \end{equation*}

  От теоремата на Кокрън следва, че
  \begin{align*}
    {[\sqrt n m_n(\eta_1, \ldots, \eta_n)]}^2 &\in \distr{\chi^2}(1),
    \\
    (n-1) s_n^2(\eta_1, \ldots, \eta_n) &\in \distr{\chi^2}(n - 1)
  \end{align*}
  и освен това двете са независими.

  Изразено чрез оригиналната извадка \( \xi_1, \ldots, \xi_n \), получаваме:
  \begin{enumerate}
    \item Оценката на очакването \( m_n \) е \( \distr{No}(\mu, n \sigma^2) \)-разпределена. Наистина,
    \begin{align*}
      {\parens*{\frac 1 {\sqrt n} \sum_{k=1}^n \frac {\xi_k - \mu} \sigma }}^2
      &=
      {\parens*{ \sqrt n \frac {m_n(\xi_1, \ldots, \xi_n) - \mu} \sigma }}^2
      = \\ &=
      {[\sqrt n \cdot m_n(\eta_1, \ldots, \eta_n)]}^2
      \in
      \distr{\chi^2}(1),
    \end{align*}
    следователно
    \begin{align*}
      \sqrt n \frac {m_n(\xi_1, \ldots, \xi_n) - \mu} \sigma &\in \distr{No}(0, 1),
      \\
      m_n(\xi_1, \ldots, \xi_n) &\in \distr{No} \parens*{\mu, \frac {\sigma^2} n }.
    \end{align*}

    \item Коригираната оценка на дисперсията \( (n-1) \frac {s_n^2} {\sigma^2} \) е \( \distr{\chi^2}(n-1) \)-разпределена. Наистина,
    \begin{equation*}
      (n-1) \frac {s_n^2(\xi_1, \ldots, \xi_n)} {\sigma^2}
      =
      (n-1) s_n^2(\eta_1, \ldots, \eta_n)
      \in
      \distr{\chi^2}(n - 1).
    \end{equation*}

    \item Оценките \( m_n \) и \( s_n^2 \) за оригиналната извадка са независими, тъй като съответните оценки за стандартизираната извадка са техни афинни преобразования и са независими.
  \end{enumerate}
\end{proof}

Това твърдение мотивира следната дефиниция
\begin{definition}
  Стандартизация на извадката \( \xi_1, \ldots, \xi_n \) наричаме случайната величина
  \begin{equation*}
    \sqrt n \frac {m_n - \mu} \sigma \in \distr{No}(0, 1).
  \end{equation*}

  Аналогично на стандартизацията, \textbf{стюдентизация} наричаме случайната величина
  \begin{equation*}
    \sqrt n \frac {m_n - \mu} {s_n} \in \distr{t}(n - 1).
  \end{equation*}
\end{definition}

\begin{remark}
  Стюдентизацията има разпределение на Стюдънт, тъй като според \cref{thm:normal_mean_variance_estimators_independent} оценките \( m_n \) и \( s_n \) са независими.
\end{remark}

\subsubsection{Доверителен интервал за очакването при известна дисперсия}

Със \( z_p \) ще означаваме \( p \)-квантила на стандартното нормално разпределение, т.е.
\begin{equation*}
  \Phi(z_p) = p.
\end{equation*}

Да забележим, че стандартното нормално разпределение е симетрично около нулата, за нас е достатъчно да знаем само един от двата квантила
\begin{equation*}
  -z_{\frac {1-\gamma} 2}
  =
  z_{1-\frac {1+\gamma} 2}
  =
  z_{\frac {1+\gamma} 2}.
\end{equation*}

Разглеждаме следния \( \gamma \)-доверителен интервал с ниво на доверие
\begin{align*}
  \Prob \parens*{ z_{\frac {1-\gamma} 2} \leq \sqrt n \frac {m_n - \mu} \sigma \leq -z_{\frac {1-\gamma} 2} = z_{\frac {1+\gamma} 2} } &= \gamma,
  \\
  \Prob \parens*{ -z_{\frac {1-\gamma} 2} \leq \sqrt n \frac {\mu - m_n} \sigma \leq z_{\frac {1-\gamma} 2} } &= \gamma,
  \\
  \Prob \parens*{ m_n - \frac \sigma {\sqrt n} z_{\frac {1-\gamma} 2} \leq \mu \leq m_n + \frac \sigma {\sqrt n} z_{\frac {1-\gamma} 2} } &= \gamma.
\end{align*}

\subsubsection{Доверителен интервал за очакването при неизвестна дисперсия}

С \( {\distr{t}(m)}_p \) ще означаваме \( p \)-квантила на \( \distr{t}(m) \) разпределението на Стюдънт.

Аналогично със случая с известно средно, но използвайки стюдентизация вместо стандартизация, получаваме интервала
\begin{equation*}
  \Prob \parens*{ m_n - \frac {s_n} {\sqrt n} \cdot {\distr{t}(n-1)}_{\frac {1-\gamma} 2} \leq \mu \leq m_n + \frac {s_n} {\sqrt n} \cdot {\distr{t}(n-1)}_{\frac {1-\gamma} 2} } = \gamma.
\end{equation*}

\subsubsection{Доверителен интервал за стандартното отклонение}

С \( {\distr{\chi^2}(m)}_p \) ще означаваме \( p \)-квантила на \( \distr{\chi^2}(m) \) разпределението.

Тъй като според \cref{thm:normal_mean_variance_estimators_independent} имаме \( (n-1) \frac {s_n^2} {\sigma^2} \in \distr{\chi^2}(n-1) \), директно намираме \( \gamma \)-доверителния интервал
\begin{align*}
  \Prob \parens*{ {\distr{\chi^2}(n-1)}_{\frac {1-\gamma} 2} \leq (n-1) \frac {s_n^2} {\sigma^2} \leq {\distr{\chi^2}(n-1)}_{\frac {1+\gamma} 2} } &= \gamma,
  \\
  \Prob \parens*{ \frac {{\distr{\chi^2}(n-1)}_{\frac {1-\gamma} 2}} {(n-1) s_n^2} \leq \frac 1 {\sigma^2} \leq \frac {{\distr{\chi^2}(n-1)}_{\frac {1+\gamma} 2}} {(n-1) s_n^2} } &= \gamma,
  \\
  \Prob \parens*{ \frac {(n-1) s_n^2} {{\distr{\chi^2}(n-1)}_{\frac {1+\gamma} 2}} \leq \sigma^2 \leq \frac {(n-1) s_n^2} {{\distr{\chi^2}(n-1)}_{\frac {1-\gamma} 2}} } &= \gamma.
\end{align*}

\printbibliography

\end{document}
