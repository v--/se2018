\documentclass{../../common/topic}

\TopicSetup{
  number=2,
  title={Симетрични оператори в крайномерни евклидови пространства. Основни свойства. Теорема за диагонализация.},
  basedate={5 юли 2019},
  author={Янис Василев}
}

% Bibliography
\addbibresource{./references.bib}

\begin{document}

\maketitle

\section{Теория}

Някои твърдения и доказателства са заимствани от \cite{Knapp} и \cite{RoyachkiNotes}.

\subsection{Анотация}

Изложената анотацията е взета от \cite{Syllabus}.

\begin{enumerate}
  \item Определение за симетричен оператор и матрица на симетричен оператор
  \item Всички характеристични корени на симетричен оператор са реални числа
  \item Всеки два вектора, съответстващи на различни собствени стойности, са ортогонални
  \item Съществува ортонормиран базис на пространството, в който матрицата на симетричен оператор е диагонална
\end{enumerate}

\subsection{Основни понятия}

Нека \( V_n \) е фиксирано \( n \)-мерно евклидово пространство над полето \( \BbbR \), т.е. \( \BbbR \)-линейно пространство снабдено със скаларно произведение \( \inprod \cdot \cdot \).

\begin{definition}
  \hfill
  \begin{enumerate}
    \item Линейният оператор \( L: V_n \to V_n \) наричаме \textbf{симетричен}, ако за произволен вектор \( x \in V_n \) е изпълнено равенството
    \begin{equation*}
      \inprod x {L(x)} = \inprod {L(x)} x.
    \end{equation*}

    \item Квадратната матрица \( A \in \BbbR^{n \times n} \) наричаме \textbf{симетрична}, ако \( A = A^T \).
  \end{enumerate}
\end{definition}

\begin{theorem}
  Симетричните оператори имат симетрични матрици.
\end{theorem}
\begin{proof}
  Нека \( e_1, \ldots, e_n \) е (нареден) ортонормиран базис на \( V_n \), нека \( L: V_n \to V_n \) е линеен оператор и нека \( A = {(a)}_{i,j} \) е матрицата на \( L \) спрямо \( e_1, \ldots, e_n \).

  Да отбележим първо, че действието на оператора върху произволен вектор се определя напълно от действието му върху базисните вектори.

  За произволни базисни вектори \( e_i \) и \( e_j \) имаме
  \begin{equation*}
    \inprod {e_i} {L(e_j)}
    =
    \inprod* {e_i} {\sum_{k=1}^n a_{k,j} e_k}
    =
    \sum_{k=1}^n a_{k,j} \inprod {e_i} {e_k}
    =
    \sum_{k=1}^n a_{k,j} \delta_{i,k}
    =
    a_{i,j}.
  \end{equation*}

  \SufficiencySubProof Ако операторът \( L \) е симетричен, за произволни базисни вектори получаваме
  \begin{equation*}
    a_{i,j}
    =
    \inprod {e_i} {L(e_j)}
    =
    \inprod {L(e_i)} {e_j}
    =
    \inprod {e_j} {L(e_i)}
    =
    a_{j,i}.
  \end{equation*}
  Следователно матрицата \( A \) е симетрична.

  \NecessitySubProof Обратно, ако матрицата \( A \) е симетрична, за произволни базисни вектори получаваме
  \begin{equation*}
    \inprod {e_i} {L(e_j)}
    =
    a_{i,j}
    =
    a_{j,i}
    =
    \inprod {e_j} {L(e_i)}
    =
    \inprod {L(e_i)} {e_j}.
  \end{equation*}
  Следователно операторът \( L \) е симетричен.
\end{proof}

\subsection{Собствени стойности на симетрични оператори}

Тъй като в общия случай корените на характеристичния полином на линеен оператор могат да не бъдат реални числа, ще работим с по-базови понятия от собствени стойности и собствени вектори, тъй като не разполагаме с необходимия апарат за комплексни линейни пространства. В частност, \enquote{имитираме} комплексно скаларно произведение.

\begin{theorem}
  Корените на характеристичния полином \( \det(A - \lambda I_n) \) на симетрична матрица \( A \in \BbbR^{n \times n} \) са реални числа.
\end{theorem}

\begin{proof}
  Нека \( \lambda \in \BbbC \) е корен на характеристичния полином \( \det(A - \lambda I_n) \). Ще покажем, че \( \lambda \in \BbbR \).

  Тъй като \( \det(A - \lambda I_n) = 0 \), матрицата \( A - \lambda I_n \) има нетривиално ядро и значи съществува ненулев комплексен вектор \( x = (x_1, \ldots, x_n) \in \BbbC^n \), такъв че
  \begin{equation*}
    (A - \lambda I_n) x = x,
  \end{equation*}
  което е еквивалентно на равенството
  \begin{equation*}
    A x = \lambda x
  \end{equation*}
  и на системата
  \begin{equation*}
    \sum_{j=1}^n a_{i,j} x_j = \lambda x_i, i = 1, \ldots, n.
  \end{equation*}

  За фиксирано \( i \) умножаваме двете страни на равенството с комплексно спрегнатото \( \overline{x_i} \) на \( x_i \) и сумираме по \( i \), за да получим
  \begin{align*}
    \sum_{j=1}^n a_{i,j} x_j
    &=
    \lambda x_i \ \mid \ \cdot \; \overline{x_i}
    \\
    \sum_{j=1}^n a_{i,j} \overline{x_i} x_j
    &=
    \lambda x_i \overline{x_i} = \lambda \abs{x_i}^2\; \mid \sum_{i=1}^n \cdot
    \\
    \sum_{i=1}^n \sum_{j=1}^n a_{i,j} \overline{x_i} x_j
    &=
    \lambda \sum_{i=1}^n \abs{x_i}^2.
  \end{align*}

  Поради симетричността на матрицата \( A \) е изпълнено
  \begin{equation*}
    \overline{a_{i,j} \overline{x_i} x_j}
    =
    a_{j,i} x_i \overline{x_j},~i, j = 1, \ldots, n,
  \end{equation*}
  следователно
  \begin{align*}
    \overline{\lambda \sum_{i=1}^n \abs{x_i}^2}
    &=
    \overline{\sum_{i=1}^n \sum_{j=1}^n a_{i,j} \overline{x_i} x_j}
    = \\ &=
    \sum_{i=1}^n \sum_{j=1}^n \overline{a_{i,j} \overline{x_i} x_j}
    = \\ &=
    \sum_{i=1}^n \sum_{j=1}^n a_{j,i} \overline{x_j} x_i
    = \\ &=
    \sum_{i=1}^n \sum_{j=1}^n a_{i,j} \overline{x_i} x_j
    = \\ &=
    \lambda \sum_{i=1}^n \abs{x_i}^2.
  \end{align*}

  Тъй като \( \sum_{i=1}^n \abs{x_i}^2 > 0 \), получаваме, че \( \lambda = \overline{\lambda} \) и \( \lambda \in \BbbR \).
\end{proof}

\begin{corollary}
  Симетричните оператори над \( V_n \) имат \( n \) собствени стойности, броейки кратностите.
\end{corollary}

\subsection{Спектрална теорема}

\begin{theorem}[Спектрална теорема]
  Собствените вектори на симетричен оператор над \( V_n \) образуват ортонормиран базис във \( V_n \).
\end{theorem}
\begin{proof}
  Ще докажем теоремата с индукция по \( n \). За \( n = 1 \) линейните оператори са умножение с число, следователно всеки линеен оператор \( L: V_1 \to V_1 \) е симетричен и има за собствен вектор числото \( 1 \).

  Нека \( n > 1 \). Допускаме, че теоремата е вярна за всички линейни пространства над \( \BbbR \) с размерност \( < n \).

  Нека \( L: V_n \to V_n \) е симетричен оператор, \( \lambda \) е собствена стойност на \( L \) и \( v \) е съответния собствен вектор. Разглеждаме ортогоналното допълнение \( U \) на \( \linspan \set{ v } \), т.е.
  \begin{equation*}
    U = \set{ u \in V_n \mid \inprod u v = 0 }.
  \end{equation*}

  Множествата \( \linspan \set{ v } \) и \( U \) не се пресичат, директната им сума е цялото пространство \( V_n \) и \( \linspan \set{ v } \) е едномерно линейно подпространство на \( V_n \), следователно \( U \) е \( n-1 \)-мерно подпространство.

  Ще покажем, че подпространството \( U \) е инвариантно относно \( L \), т.е. \( L(U) \subseteq U \). За произволен вектор \( u \in U \) имаме
  \begin{equation*}
    \inprod {L(u)} v
    =
    \inprod u {L(v)}
    =
    \inprod u {\lambda v}
    =
    \lambda \inprod u v
    =
    0.
  \end{equation*}

  Следователно \( \inprod u v = 0 \) и \( L(u) \in U \).

  Прилагаме индуктивната хипотеза към рестрикцията \( L_U \) на оператора \( L \) върху \( U \) и получаваме ортонормиран базис \( e_1, \ldots, e_{n-1} \) на \( U \) от собствени вектори на \( L \). Всички те са ортогонални на \( v \) като елементи на \( U \), следователно системата вектори \( e_1, \ldots, e_{n-1}, v \) образува ортонормиран базис на \( V_n \), състоящ се от собствени вектори на \( L \).
\end{proof}

\begin{corollary}
  Всеки два собствени вектора на симетричен оператор над \( V_n \), съответстващи на различни собствени стойности, са ортогонални.
\end{corollary}

\begin{corollary}
  Симетричните оператори над \( V_n \) имат диагонални матрици спрямо базисите си от собствени стойности.
\end{corollary}

\section{Задачи}

\subsection{Анотация}

\begin{enumerate}
  \item За даден симетричен оператор да се намерят ортонормиран базис на пространството, в който матрицата му е диагонална, както и самата матрица.
\end{enumerate}

\subsection{Диагонализация на симетричен оператор}

\begin{problem}[\cite{SEAutumn2011}]
  Спрямо ортонормиран базис на евклидовото пространство \( \BbbR^3 \), линейният оператор \( \varphi: \BbbR^3 \to \BbbR^3 \) има матрица
  \begin{align*}
    A = \begin{pmatrix}
      1 & p & 0 \\
      p & 0 & 2 \\
      0 & 2 & -1
    \end{pmatrix},
  \end{align*}
  зависеща от реален параметър \( p \). Да се пресметнат стойностите на реалния параметър \( p \), за които характеристичният полином \( f_\varphi(x) \) на \( \varphi \) изпълнява равенството \( f_\varphi(2) = 10 \). За получените стойности на \( p \) да се намери ортонормиран базис \( e_1, e_2, e_3 \) в \( \BbbR^3 \), в който матрицата \( D \) на \( \varphi \) е диагонална, както и тази диагонална матрица \( D \).
\end{problem}
\begin{solution}
  Първо намираме характеристичния полином на \( \varphi \):
  \begin{align*}
    f_\varphi(\lambda)
    &=
    \det(A - \lambda I)
    = \\ &=
    \det \begin{pmatrix}
      1 - \lambda & p & 0 \\
      p & -\lambda & 2 \\
      0 & 2 & -1-\lambda
    \end{pmatrix}
    = \\ &=
    (1-\lambda) (-\lambda) (-1-\lambda) + 0 + 0 - 0 - (1-\lambda) 2^2 - (-1-\lambda) p^2
    = \\ &=
    \lambda (1 - \lambda) (1 + \lambda) + 4 (\lambda - 1) + (\lambda + 1) p^2
    = \\ &=
    -\lambda^3 + (5 + p^2) \lambda + (p^2 - 4).
  \end{align*}

  Получаваме следното уравнение за \( p \):
  \begin{equation*}
    f_\varphi(2) = -2^3 + 2 (5+p^2) + (p^2-4) = 3 p^2 - 2 = 10,
  \end{equation*}
  което има решения \( p = \pm 2 \).

  Тъй като \( p \) участва в характеристичния полином само чрез квадрата си \( p^2 \), и в двата случая за характеристичния полином получаваме
  \begin{equation*}
    f_\varphi(\lambda) = -\lambda^3 + 9 \lambda = -\lambda(\lambda^2 - 9) = \boxed{-\lambda (\lambda - 3) (\lambda + 3)}.
  \end{equation*}

  Собствените стойности са \( \lambda_1 = 0 \), \( \lambda_2 = 3 \) и \( \lambda_3 = -3 \).

  Както ще се убедим по-късно, матрицата \( D \) на \( \varphi \) спрямо наредения базис от собствени вектори, съответстващи на намерените собствени стойности, е
  \begin{align*}
    \begin{pmatrix}
      \lambda_1 & 0 & 0 \\
      0 & \lambda_2 & 0 \\
      0 & 0 & \lambda_3
    \end{pmatrix}
    =
    \begin{pmatrix}
      0 & 0 & 0 \\
      0 & 3 & 0 \\
      0 & 0 & -3.
    \end{pmatrix}
  \end{align*}

  Съответстващите собствени вектори \( e_k, k = 1, 2, 3 \) намираме от системата
  \begingroup
  \allowdisplaybreaks
  \begin{align*}
    A e_k &= 0 \cdot e_k,
    \\
    \begin{pmatrix}
      1 & \pm 2 & 0 \\
      \pm 2 & 0 & 2 \\
      0 & 2 & -1
    \end{pmatrix}
    \begin{pmatrix}
      e_{1,k} \\ e_{2,k} \\ e_{3,k}
    \end{pmatrix}
    &=
    \lambda_k
    \begin{pmatrix}
      e_{1,k} \\ e_{2,k} \\ e_{3,k}
    \end{pmatrix}.
  \end{align*}
  \endgroup

  От първото уравнение следва
  \begin{align*}
    e_{1,k} \pm 2 e_{2,k} &= \lambda e_{1,k},
    \\
    \pm 2 e_{2,k} &= (\lambda - 1) e_{1,k},
    \\
    e_{2,k} &= \pm \frac {\lambda - 1} 2 e_{1,k},
  \end{align*}
  а от третото следва
  \begin{align*}
    2e_{2,k} - e_{3,k} &= \lambda e_{3,k},
    \\
    2 e_{2,k} &= (\lambda + 1) e_{3,k},
    \\
    e_{3,k} &= \frac 2 {\lambda + 1} e_{2,k},
    \\
    e_{3,k} &= \pm \frac {\lambda - 1} {\lambda + 1} e_{1,k}.
  \end{align*}

  Тъй като искаме собствените вектори да бъдат нормирани, имаме ограничението
  \begin{align*}
    {\norm{e_k}}^2
    &=
    \inprod{e_k} {e_k}
    = \\ &=
    {e_{1,k}}^2 + {\parens*{\pm \frac {\lambda - 1} 2 e_{1,k} }}^2 + {\parens*{\pm \frac {\lambda - 1} {\lambda + 1} e_{1,k} }}^2
    = \\ &=
    {e_{1,k}}^2 \bracks*{1 + {\parens*{\frac {\lambda - 1} 2 }}^2 + {\parens*{\frac {\lambda - 1} {\lambda + 1} }}^2 }
    =
    1.
  \end{align*}

  За конкретните собствени стойности получаваме
  \begin{align*}
    {e_{1,1}}^2 \bracks*{1 + {\parens*{ - \tfrac 1 2 }}^2 + {(-1)}^2 } &= \frac 9 4 {e_{1,1}}^2 = 1 \implies e_{1,1} = \frac 2 3 \implies e_{2,1} = \mp \frac 1 3 \implies e_{3,1} = \mp \frac 2 3,
    \\
    {e_{1,2}}^2 \bracks*{1 + 1^2 + {\parens*{ \frac 1 2 }}^2 } &= \frac 9 4 {e_{2,1}}^2 = 1 \implies e_{1,2} = \frac 2 3 \implies e_{2,2} = \pm \frac 2 3 \implies e_{3,2} = \pm \frac 1 3,
    \\
    {e_{1,3}}^2 \parens*{1 + {(-2)}^2 + 2^2 } &= 9 \cdot {e_{1,3}^2} = 1 \implies e_{1,3} = \frac 1 3 \implies e_{2,3} = \mp \frac 2 3 \implies e_{2,3} = \pm \frac 2 3.
  \end{align*}

  Следователно базисите от собствени стойности за \( p = \pm 2 \) има матрица
  \begin{align*}
    E = \begin{bmatrix} e_1 \mid e_2 \mid e_3 \end{bmatrix} = \frac 1 3 \begin{pmatrix}
          2 &     2 &     1 \\
      \mp 1 & \pm 2 & \mp 2 \\
      \mp 2 & \pm 1 & \pm 2
    \end{pmatrix}.
  \end{align*}

  Остана да се уверим, че \( A E = E D \). Наистина,
  \begingroup
  \allowdisplaybreaks
  \begin{align*}
    A E
    &=
    \frac 1 3
    \begin{pmatrix}
      1 & \pm 2 & 0 \\
      \pm 2 & 0 & 2 \\
      0 & 2 & -1
    \end{pmatrix}
    \begin{pmatrix}
          2 &     2 &     1 \\
      \mp 1 & \pm 2 & \mp 2 \\
      \mp 2 & \pm 1 & \pm 2
    \end{pmatrix}
    = \\ &=
    \frac 1 3
    \begin{pmatrix}
      2 - 2     & 2 + 4         & 1 - 4 \\
      \pm 4 \mp 4 & \pm 6       & \pm 2 \pm 4 \\
      \mp 2 \pm 2 & \pm 4 \mp 1 & \mp 4 \mp 2
    \end{pmatrix}
    = \\ &=
    \frac 1 3
    \begin{pmatrix}
      0 & 6     & -3 \\
      0 & \pm 6 & \pm 6 \\
      0 & \pm 3 & \mp 6
    \end{pmatrix}
    = \\ &=
    \frac 1 3
    \begin{pmatrix}
          2 &     2 &     1 \\
      \mp 1 & \pm 2 & \mp 2 \\
      \mp 2 & \pm 1 & \pm 2
    \end{pmatrix}
    \begin{pmatrix}
      0 & 0 & 0 \\
      0 & 3 & 0 \\
      0 & 0 & -3
    \end{pmatrix}
    =
    E D.
  \end{align*}
  \endgroup
\end{solution}

\printbibliography

\end{document}
