\documentclass[numbers=endperiod, bibliography=totocnumbered]{scrartcl}

\usepackage{../../common/common_packages}
\usepackage{../../common/macros}
\usepackage{../../common/theorem_styles}

% Bibliography
\addbibresource{./references.bib}

% Document
\title{Тема 19 от \URL{https://github.com/v--/se2018}}
\subtitle{Проверка на хипотези.}
\author{Янис Василев}
\date{Оригинал: 28 юни 2019 \\ Ревизия: \gitAbbrevHash{} (\gitAuthorDate) \\ За всеки случай проверете, дали няма по-нова ревизия}

\begin{document}

\maketitle

\section{Теория}

Лемата на Нейман-Пирсън е базирана на изложението ѝ в~\cite{DimitrovYanev}.

\subsection{Анотация}

Изложената анотацията е взета от конспекта~\cite{Syllabus} за 2018г.

\begin{enumerate}
  \item Определение за статистичека хипотеза
  \item Прости и сложни хипотези
  \item Определения за грешки от първи и твори род, критична област, мощност, значимост на тест и значимост на статистиката на теста
  \item Лема на Нейман–Пирсън
\end{enumerate}

\subsection{Основни понятия}

Считаме, че е зададено вероятностно пространство \( (\Omega, \F, \Prob) \).

\begin{definition}[Извадки]
  Нека \( \xi \) е случайна величина над \( (\Omega, \F, \Prob) \). Множеството от елементарни събития \( \Omega \) в статистиката често се нарича \textbf{генерална съвкупност}.

  \begin{itemize}
    \item Ако случайните величини \( \xi_1, \ldots, \xi_n \) са независими две по две и имат същото разпределение като \( \xi \), казваме, че \( \xi_1, \ldots, \xi_n \) са \textbf{наблюдения} над \( \xi \) и че те са \textbf{проста извадка} с обем \( n \) над генералната съвкупност \( \Omega \). Понякога ги разглеждаме и като случаен вектор \( \V{\xi_n} = (\xi_1, \ldots, \xi_n) \).
    \item \textbf{Функция на правдоподобие} \( l_\xi(x) \) на случайната величина \( \xi \) наричаме, в абсолютно непрекъснатия случай, плътността на \( \xi \) или, в дискретния случай, функцията на вероятностите на \( \xi \).
    \item \textbf{Функция на правдоподобие} \( l(x_1, \ldots, x_n) \) на извадката \( \xi_1, \ldots, \xi_n \) наричаме функцията на правдоподобие на случайния вектор \( \V{\xi_n} \). При извадки от независими случайни величини, функцията на правдоподобие на извадката е произведение на индивидуалните функции на правдоподобие.
    \item \textbf{Извадково} пространство, съответстващо на извадката \( \xi_1, \ldots, \xi_n \), наричаме множеството \( \SampleSpace \subseteq \R^n \) от стойности на случайния вектор \( \V{\xi_n} \).
    \item \textbf{Реализации} на извадката наричаме вектори от \( \SampleSpace \). Те моделират истинските данни в математическата статистика, съпоставяйки ги на \enquote{теоретичната} извадка \( \xi_1, \ldots, \xi_n \).
  \end{itemize}
\end{definition}

\begin{definition}[Хипотези]
  Нека \( \xi_1, \ldots \xi_n \) е проста извадка над случайната величина \( \xi \), чието разпределение не ни е известно.

  \begin{itemize}
    \item Всяко предположение за разпределението на \( \xi \) наричаме \textbf{статистическа хипотеза}. Формално, хипотезата \( H \) често се представя като множество от възможни функции на разпределение на \( \xi \). При повече от една хипотеза, искаме те да не се пресичат. Условна вероятност при условие, че \( F_\xi \in H \), обикновена записваме чрез
    \begin{equation*}
      \Prob(\cdot \mid H).
    \end{equation*}

    Обикновено се разглеждат само две хипотези: \textbf{нулевата хипотеза} \( H_0 \) и \textbf{алтернативната хипотеза} \( H_1 \).

    \item При \textbf{параметричната} статистика хипотезите се отнасят за параметри на семейства от разпределения, например за очакването \( \mu \) на нормално разпределение или степента \( \lambda \) на поасоново разпределение. В противен случай говорим за \textbf{непараметрична} статистика. В непараметричния случай считаме, че двете хипотези съдържат едновременно само дискретни или само непрекъснати разпределения.

    \item За да направим заключение за верността на една хипотеза ни е необходим \textbf{статистически критерий}. Формално, статистическите критерии са изображения \( \delta: \SampleSpace \to \{ H_0, H_1 \} \), съпоставящи на реализация на извадка някоя хипотеза. Да отбележим, че критерият \( \delta \) сам по себе си е случайна величина.

    \item Един критерий ни казва коя хипотеза да \textbf{приемем} и коя да \textbf{отхвърлим}, обикновено на базата на данни от експеримент, т.е. на някоя реализация на извадка над \( \xi \). Поради случайния характер на експериментите, обаче, при практически задачи е възприета терминологията \enquote{имаме/нямаме основание да отхвърлим хипотезата \( H \) на база на данните} или \enquote{хипотезата \( H \) е/не е съвместима с данните}.

    \item \textbf{Статистически тест} наричаме набор от хипотези и съгласуван с тях критерии.

    \item Вероятността \( \alpha \) за \textbf{грешка от първи род} или \textbf{ниво на съгласие} или \textbf{ниво на значимост} е вероятността да отхвърлим вярна нулева хипотеза, т.е.
    \begin{equation*}
      \alpha \coloneqq \Prob(\delta = H_1 \mid H_0).
    \end{equation*}

    Стойността \( \gamma \coloneqq 1 - \alpha \) наричаме \textbf{значимост} или \textbf{ниво на доверие} на теста.

    \item \enquote{Вероятността \( \beta \) за грешка от втори род} е вероятността да приемем грешна нулева хипотеза, т.е.
    \begin{equation*}
      \beta \coloneqq \Prob(\delta = H_0 \mid H_1).
    \end{equation*}

    Стойността \( \pi \coloneqq 1 - \beta \) наричаме \textbf{мощност} на теста.

    \item \textbf{Критична област} \( W_\alpha \) с ниво на значимост \( \alpha \) наричаме произволно множество \( W_\alpha \subsetneq \SampleSpace \) от реализации на извадката с \( \Prob(\V{\xi_n} \in W \mid H_0) = \alpha \), попадайки в което \textbf{отхвърляме} нулевата хипотеза.

    Всяка критична област задава критерия
    \begin{equation*}
      \delta(x) = \begin{cases}
        H_1, x \in W, \\
        H_0, x \not\in W.
      \end{cases}
    \end{equation*}

    \item Нека са зададени хипотезите \( H_0 \) и \( H_1 \) и е фиксирано ниво на значимост \( \alpha \). Критичната област
    \begin{equation*}
      W_\alpha^* \coloneqq \Argmax_{W_\alpha \subsetneq \SampleSpace} \Prob(\V{\xi_n} \in W_\alpha \mid H_1),
    \end{equation*}
    осигуряваща най-голяма мощност на теста, наричаме~\textbf{оптимална критична област}.

    \item Хипотезата наричаме \textbf{проста}, ако на нея отговаря точно едно разпределение. В противен случая я наричаме \textbf{сложна}. Ако имаме една проста хипотеза и една сложна, избираме нулевата да бъде проста. Така имаме три случая:
    \begin{enumerate}
      \item Проста хипотеза срещу проста алтернатива,
      \item Проста хипотеза срещу сложна алтернатива,
      \item Сложна хипотеза срещу сложна алтернатива.
    \end{enumerate}

    \item Разглеждаме тест с две хипотези \( H_0 \) и \( H_1 \) като множества от възможни функции на разпределение на \( \xi \). Имаме три случая
    \begin{itemize}
      \item Ако \( F_1(x) \leq F_0(x)~\forall F_0 \in H_0, F_1 \in H_1 \), наричаме теста \textbf{ляв едностранен}
      \item Ако \( F_1(x) \geq F_0(x)~\forall F_0 \in H_0, F_1 \in H_1 \), наричаме теста \textbf{десен едностранен}
      \item В противен случай, наричаме теста \textbf{двустранен}
    \end{itemize}

    \item Нека \( H_0 \) е проста хипотеза и \( x = (x_1, \ldots, x_n) \in \SampleSpace \) е реализация на извадка. \textbf{Значимост} или \( p \)-\textbf{стойност} на реализацията \( x \) наричаме условната вероятност спрямо нулева хипотеза \( H_0 \) на опашките на разпределението на \( \xi \), определени от типа на теста.

    В зависимост от типа на теста разполагаме с няколко формални определения за значимост на реализация:
    \begin{align*}
      p \coloneqq \begin{cases}
        \Prob(x \geq \xi \mid H_0), &\text{ за леви едностранни тестове} \\
        \Prob(x \leq \xi \mid H_0), &\text{ за десни едностранни тестове} \\
        2 \min (\Prob(x \leq \xi \mid H_0), \Prob(x \geq \xi \mid H_0)) &\text{ за двустранни тестове}
      \end{cases}
    \end{align*}

    Често се казва, че значимостта на \( x \) е вероятността да наблюдаваме \enquote{по-екстремна} стойност от \( x \).
  \end{itemize}
\end{definition}

\subsection{Лема на Нейман-Пирсън}

\begin{lemma}[Нейман-Пирсън]
  Нека са дадени две прости хипотези за функцията на правдоподобие на извадка \( \xi_1, \ldots, \xi_n \) над случайна величина \( \xi \),
  \begin{align*}
    \begin{cases}
      H_0: &l(x) = l_0(x) \\
      H_1: &l(x) = l_1(x).
    \end{cases}
  \end{align*}

  Считаме, че е зададено ниво на съгласие \( \alpha \). Ако за някоя реална константа \( c > 0 \) за критичната област \( W_\alpha \) са изпълнени неравенствата
  \begin{align*}
    &l_0(x) \leq c \cdot l_1(x), x \in W_\alpha, \\
    &l_0(x) \geq c \cdot l_1(x), x \not\in W_\alpha,
  \end{align*}
  тогава \( W_\alpha \) е оптимална критична област.
\end{lemma}

\begin{remark}
  В общия случай стойностите \( x \in \SampleSpace \), за които \( l_0(x) = cl_1(x) \), могат както да лежат в критичната област, така и извън нея.
\end{remark}

\begin{proof}
  Ще докажем теоремата само за абсолютно непрекъснати разпределения. В общия случай римановите интеграли могат да се заменят с интеграли по вероятностни мерки, съответстващи на двете хипотези.

  Нека \( U_\alpha \) е произволна друга критична област за същия тест с ниво на съгласие \( \alpha \). Означаваме \( Q(A) \coloneqq \Prob(\V{\xi_n} \in A) \).

   Ще докажем, че \( Q(U_\alpha \mid H_1) \geq Q(W_\alpha \mid H_1) \). Поради адитивността на вероятностните мерки имаме
  \begin{align*}
    &\hspace{0.45cm}Q(W_\alpha \mid H_1) - Q(U_\alpha \mid H_1)
    = \\ &=
    Q((U_\alpha \cap W_\alpha) \cup (W_\alpha \setminus U_\alpha) \mid H_1) - Q((U_\alpha \cap W_\alpha) \cup (U_\alpha \setminus W_\alpha) \mid H_1)
    = \\ &=
    Q(U_\alpha \cap W_\alpha \mid H_1) + Q(W_\alpha \setminus U_\alpha \mid H_1) - Q(U_\alpha \cap W_\alpha \mid H_1) - Q(U_\alpha \setminus W_\alpha \mid H_1)
    = \\ &=
    Q(W_\alpha \setminus U_\alpha \mid H_1) - Q(U_\alpha \setminus W_\alpha \mid H_1)
    = \\ &=
    \int_{W_\alpha \setminus U_\alpha} l_1(x) dx + \int_{U_\alpha \setminus W_\alpha} (-l_1(x)) dx
    \geq \\ &\geq
    \frac 1 c \int_{W_\alpha \setminus U_\alpha} l_0(x) dx + \frac 1 c \int_{U_\alpha \setminus W_\alpha} (-l_0(x)) dx
    = \\ &=
    \frac 1 c \left( \int_{W_\alpha \setminus U_\alpha} l_0(x) dx - \int_{U_\alpha \setminus W_\alpha} l_0(x) dx \right)
    = \\ &=
    \frac 1 c [Q(W_\alpha \setminus U_\alpha \mid H_0) - Q(U_\alpha \setminus W_\alpha \mid H_0)]
    = \\ &=
    \frac 1 c [Q(U_\alpha \cap W_\alpha \mid H_0) + Q(W_\alpha \setminus U_\alpha \mid H_0) - Q(U_\alpha \cap W_\alpha \mid H_0) - Q(U_\alpha \setminus W_\alpha \mid H_0)]
    = \\ &=
    \frac 1 c [Q(W_\alpha \mid H_0) - Q(U_\alpha \mid H_0)]
    = \\ &=
    \frac 1 c (\alpha - \alpha)
    =
    0.
  \end{align*}
\end{proof}

\printbibliography

\end{document}
